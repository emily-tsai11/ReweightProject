{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json, os\n",
    "\n",
    "# define constants\n",
    "m_index = 0\n",
    "pt_index = 1\n",
    "pz_index = 2\n",
    "num_attr = 3\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load config file\n",
    "config = json.load(open(\"../config/nn_test_v1.json\"))\n",
    "events = json.load(open(config[\"FILES\"][\"events\"]))\n",
    "num_train = config[\"NUM\"][\"train\"]\n",
    "num_test = config[\"NUM\"][\"test\"]\n",
    "couplings = config[\"COUPLINGS\"]\n",
    "ckeys = couplings.keys()\n",
    "kernel_l = config[\"MODEL_PARAM\"][\"kernel_l\"]\n",
    "nro = config[\"MODEL_PARAM\"][\"nro\"]\n",
    "a = config[\"MODEL_PARAM\"][\"a\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the number of events you want don't exceed the total number of events\n",
    "if num_train + num_test > len(events):\n",
    "    print(\"the size of the training and test sets you input is greater than the number of data points available. please try again.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define custom callback\n",
    "class CustomCallback(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs = None):\n",
    "        #keys = list(logs.keys())\n",
    "        print(\"Starting training\") #; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_train_end(self, logs = None):\n",
    "        keys = list(logs.keys())\n",
    "        print(\"Stop training\") # ; got log keys: {}\".format(keys))\n",
    "        for key in keys:\n",
    "            print (\"log key = {}, val = {}\".format(key, logs[key]))\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs = None):\n",
    "        #keys = list(logs.keys())\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Start epoch {} of training\".format(epoch))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        keys = list(logs.keys())\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"End epoch {} of training\".format(epoch))\n",
    "        #for key in keys:\n",
    "        #    print (\"log key = {}, val = {}\".format(key, logs[key]))\n",
    "\n",
    "    def on_test_begin(self, logs = None):\n",
    "        keys = list(logs.keys())\n",
    "#         print(\"Start testing; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_test_end(self, logs = None):\n",
    "        keys = list(logs.keys())\n",
    "#         print(\"Stop testing; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_predict_begin(self, logs = None):\n",
    "        keys = list(logs.keys())\n",
    "#         print(\"Start predicting; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_predict_end(self, logs = None):\n",
    "        keys = list(logs.keys())\n",
    "#         print(\"Stop predicting; got log keys: {}\".format(keys))\n",
    "\n",
    "    def on_train_batch_begin(self, batch, logs = None):\n",
    "        keys = list(logs.keys())\n",
    "#         print(\"...Training: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs = None):\n",
    "        keys = list(logs.keys())\n",
    "#         print(\"...Training: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs = None):\n",
    "        keys = list(logs.keys())\n",
    "#         print(\"...Evaluating: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs = None):\n",
    "        keys = list(logs.keys())\n",
    "#         print(\"...Evaluating: end of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_predict_batch_begin(self, batch, logs = None):\n",
    "        keys = list(logs.keys())\n",
    "#         print(\"...Predicting: start of batch {}; got log keys: {}\".format(batch, keys))\n",
    "\n",
    "    def on_predict_batch_end(self, batch, logs = None):\n",
    "        keys = list(logs.keys())\n",
    "#         print(\"...Predicting: end of batch {}; got log keys: {}\".format(batch, keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, m, sd):\n",
    "    return (x - m) / sd\n",
    "\n",
    "def build_model(act = \"relu\"):\n",
    "    model = keras.Sequential([ layers.Dense(8,  activation = act, input_shape = [num_attr]), \n",
    "                               layers.Dense(32, activation = act),\n",
    "                               layers.Dense(128, activation = act),\n",
    "                               layers.Dense(32, activation = act),\n",
    "                               layers.Dense(8,  activation = act),\n",
    "                               layers.Dense(1, activation=\"sigmoid\")] )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neutal network training\n",
    "counter = 0\n",
    "for ckey in ckeys:\n",
    "    print(\"----------------------------------------------------------------------\")\n",
    "    start = time()\n",
    "\n",
    "    # define input and output coupling\n",
    "    input_coupling = \"M%2dK%03d\" % (couplings[ckey][\"Mi\"], couplings[ckey][\"Ki\"])\n",
    "    output_coupling = \"M%2dK%03d\" % (couplings[ckey][\"Mf\"], couplings[ckey][\"Kf\"])\n",
    "\n",
    "    # define save directory\n",
    "    save_dir = \"../data/plots/nn/\" + input_coupling + \"to\" + output_coupling + \"_ntr\" + str(num_train) + \"te\" + str(num_test) + \"_k\" + str(kernel_l) + \"_nro\" + str(nro) + \"_a\" + str(a) + \"/\"\n",
    "\n",
    "    # create save directory, unless it already exists\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.system(\"mkdir -p \" + save_dir)\n",
    "\n",
    "    # open runtime file\n",
    "    f = open(save_dir + \"runtimes.txt\", \"w\")\n",
    "\n",
    "    # print input and output couplings\n",
    "    print(\"coupling \" + ckey + \" of \" + str(len(ckeys)) + \":\")\n",
    "    print(\"\\tinput coupling of: \" + input_coupling)\n",
    "    print(\"\\toutput coupling of: \" + output_coupling)\n",
    "\n",
    "    f.write(\"coupling:\\n\")\n",
    "    f.write(\"\\tinput coupling of: \" + input_coupling + \"\\n\")\n",
    "    f.write(\"\\toutput coupling of: \" + output_coupling + \"\\n\")\n",
    "\n",
    "    # creating training and testing datasets\n",
    "    print(\"creating\")\n",
    "    print(\"\\ttraining dataset with \" + str(num_train) + \" events\")\n",
    "    print(\"\\ttesting dataset with \" + str(num_test) + \" events\")\n",
    "\n",
    "    f.write(\"creating\\n\")\n",
    "    f.write(\"\\ttraining dataset with \" + str(num_train) + \" events\\n\")\n",
    "    f.write(\"\\ttesting dataset with \" + str(num_test) + \" events\\n\")\n",
    "\n",
    "    ev_num_train = []\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    ev_num_test = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "\n",
    "    for i in range(num_train + num_test):\n",
    "        e = events[str(i)]\n",
    "        Top = e[\"2\"]\n",
    "        # _4vector = ROOT.TLorentzVector()\n",
    "        # _4vector.SetPxPyPzE(Top[\"px\"], Top[\"py\"], Top[\"pz\"], Top[\"e\"])\n",
    "        px, py, pz, E, m = Top[\"px\"], Top[\"py\"], Top[\"pz\"], Top[\"e\"], Top[\"m\"]\n",
    "        pt = (px**2 + py**2)**0.5\n",
    "        \n",
    "        if i < num_train:\n",
    "            ev_num_train.append(i)\n",
    "            X_train.append([m/1000., pt/1000., pz/1000.])\n",
    "            y_train.append(e[\"wts\"][output_coupling])\n",
    "        else:\n",
    "            ev_num_test.append(i)\n",
    "            X_test.append([m/1000., pt/1000., pz/1000.])\n",
    "            y_test.append(e[\"wts\"][output_coupling])\n",
    "\n",
    "            \n",
    "    # convert to numpy arrays\n",
    "    X_train,  X_test = np.array(X_train), np.array(X_test)\n",
    "    max_weight = np.max(np.array(y_train + y_test))\n",
    "    y_train, y_test = np.array(y_train)/max_weight, np.array(y_test)/max_weight\n",
    "\n",
    "    \n",
    "    # define model\n",
    "    model = build_model()\n",
    "    #optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    model.compile(loss = keras.losses.MeanAbsolutePercentageError(), \n",
    "                  optimizer = optimizer, \n",
    "                  metrics = [tf.keras.metrics.MeanAbsolutePercentageError()])\n",
    "    \n",
    "\n",
    "    # model.summary()\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs = EPOCHS, validation_split = 0.2) # verbose = 0, callbacks = [CustomCallback()])\n",
    "    # early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
    "    # history = model.fit(X_train_norm, y_train, epochs = EPOCHS, validation_split = 0.2, verbose = 0, callbacks = [early_stop, CustomCallback()])\n",
    "\n",
    "    plt.figure(counter)\n",
    "    counter += 1\n",
    "    plt.plot(history.epoch, history.history[\"mean_absolute_percentage_error\"])\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.xlim([10.0, 100.])\n",
    "    plt.ylim([0.0, 200.])\n",
    "    plt.ylabel(\"mean_absolute_percentage_error\")\n",
    "\n",
    "#     # zoomed\n",
    "#     plt.figure(counter)\n",
    "#     counter += 1\n",
    "#     plt.plot(history.epoch, history.history[\"mean_absolute_percentage_error\"])\n",
    "#     plt.ylim([0.0, 0.1])\n",
    "#     plt.xlabel(\"epoch\")\n",
    "#     plt.ylabel(\"mean_absolute_percentage_error\")\n",
    "    \n",
    "    loss, mape = model.evaluate(X_test, y_test, verbose = 2)\n",
    "    print(\"Testing set Mean Abs Percentage Error: {:5.2f}\".format(mape))\n",
    "    \n",
    "    y_predict = model.predict(X_test)\n",
    "\n",
    "    plt.figure(counter)\n",
    "    counter += 1\n",
    "    plt.scatter(y_test*max_weight, y_predict*max_weight)\n",
    "    plt.xlabel(\"true\")\n",
    "    plt.ylabel(\"prediction\")\n",
    "\n",
    "#     # zoomed\n",
    "#     plt.figure(counter)\n",
    "#     counter += 1\n",
    "#     plt.scatter(y_test, y_predict)\n",
    "#     plt.ylim([-0.05, 0.05])\n",
    "#     plt.xlabel(\"true\")\n",
    "#     plt.ylabel(\"prediction\")\n",
    "    \n",
    "    error = (y_predict - y_test) / y_test * 100\n",
    "\n",
    "    plt.figure(counter)\n",
    "    counter += 1\n",
    "    plt.hist(error, bins = 50)\n",
    "    plt.xlabel(\"percent error\")\n",
    "    plt.ylabel(\"count\")\n",
    "\n",
    "    # zoomed\n",
    "    plt.figure(counter)\n",
    "    counter += 1\n",
    "    plt.hist(error, bins = 50)\n",
    "    plt.xlim([-100.0, 100.0])\n",
    "    plt.xlabel(\"percent error\")\n",
    "    plt.ylabel(\"count\")\n",
    "\n",
    "    print(\"runtime: \" + str(time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:10]*10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict[0:10]*10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git config --local credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core.repositoryformatversion=0\n",
      "core.filemode=true\n",
      "core.bare=false\n",
      "core.logallrefupdates=true\n",
      "remote.origin.url=https://github.com/emily-tsai11/ReweightProject.git\n",
      "remote.origin.fetch=+refs/heads/*:refs/remotes/origin/*\n",
      "branch.master.remote=origin\n",
      "branch.master.merge=refs/heads/master\n",
      "user.email=avik3.1416@gmail.com\n",
      "credential.helper=store\n",
      "# On branch br_avik\n",
      "# Changes not staged for commit:\n",
      "#   (use \"git add <file>...\" to update what will be committed)\n",
      "#   (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
      "#\n",
      "#\tmodified:   nn.ipynb\n",
      "#\n",
      "# Untracked files:\n",
      "#   (use \"git add <file>...\" to include in what will be committed)\n",
      "#\n",
      "#\t../data/plots/\n",
      "#\t.ipynb_checkpoints/\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    }
   ],
   "source": [
    "! git config --local --list\n",
    "! git status\n",
    "! git add nn.ipynb\n",
    "! git commit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (yorkiva_py36)",
   "language": "python",
   "name": "yorkiva_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
